{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from FISHClass.datasets import MYCN\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from baseline import models\n",
    "from FISHClass.utils.evaluation import get_top_model\n",
    "from FISHClass.evaluation.evaluate_test_set import predict_test, predict_test_baseline\n",
    "from FISHClass.models import CombinedModel\n",
    "from FISHClass.utils.device import best_gpu\n",
    "import os\n",
    "import torch\n",
    "import FISHClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.CombinedModel.CombinedModel'>\n",
      "Using cuda:3 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:31<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.CombinedModel.CombinedModel'>\n",
      "Using cuda:1 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:37<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.ClassificationCNN.ClassificationCNN'>\n",
      "couldtn redefine\n",
      "Using cuda:3 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:08<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.ClassificationCNN.ClassificationCNN'>\n",
      "couldtn redefine\n",
      "Using cuda:3 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:07<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.FeaturespaceClassifier.FeaturespaceClassifier'>\n",
      "Using cuda:3 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:31<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'FISHClass.ModelZoo.FeaturespaceClassifier.FeaturespaceClassifier'>\n",
      "Using cuda:2 for calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:35<00:00,  1.73it/s]\n",
      "100%|██████████| 31/31 [00:07<00:00,  3.90it/s]\n",
      "100%|██████████| 31/31 [00:08<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/MYCN_SpikeIn/TRAINING.h5\"\n",
    "OUT = \"/home/simon_g/src/eval/test_set\"\n",
    "\n",
    "with open(\"/home/simon_g/src/FISHClass/evaluation/model_evaluation.yaml\") as f:\n",
    "\n",
    "    yaml_data = yaml.load(f, Loader=yaml.FullLoader)[\"trained_model_paths\"]\n",
    "\n",
    "for model_name, model_items in yaml_data.items():\n",
    "    \n",
    "    if not isinstance(model_items, str):\n",
    "        \n",
    "        if model_items[\"model_type\"] == \"AreaModel\":\n",
    "            model = getattr(models, model_items[\"model_type\"])(**model_items[\"AreaModel_kwargs\"])\n",
    "            results = predict_test_baseline(model, DATASET, dataset_kwargs={\"norm_type\": None, \"transform\": None}, save2h5=True, save_path=os.path.join(OUT, f\"{model_name}_results.h5\"))\n",
    "    \n",
    "    \n",
    "        elif model_items[\"model_type\"] == \"SpotdetectionModel\":\n",
    "\n",
    "            model = getattr(models, model_items[\"model_type\"])(**model_items[\"SpotdetectionModel_kwargs\"])\n",
    "            results = predict_test_baseline(model, DATASET, dataset_kwargs={\"norm_type\": None, \"transform\": None}, save2h5=True, save_path=os.path.join(OUT, f\"{model_name}_results.h5\"))\n",
    "        \n",
    "    else:\n",
    "        try:\n",
    "            model = torch.load(get_top_model(model_items))[\"model\"]\n",
    "        except:\n",
    "            model = torch.load(get_top_model(model_items))\n",
    "            \n",
    "        print(type(model))\n",
    "        results= predict_test(model, DATASET, device=best_gpu(), batch_size=16, \n",
    "                              dataset_kwargs={\"double_return\": isinstance(model, (FISHClass.ModelZoo.FeaturespaceClassifier.FeaturespaceClassifier, FISHClass.ModelZoo.WeightedFeaturespaceClassifier.WeightedFeaturespaceClassifier)), \n",
    "                                              \"norm_type\": model.norm_type, \n",
    "                                              \"mask\": model.mask, \n",
    "                                              \"channels\": model.channels, \n",
    "                                              \"transform\": None}, \n",
    "                              save2h5=True, \n",
    "                              save_path=os.path.join(OUT, f\"{model_name}_results.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/simon_g/src/eval/test_set/Basic-Classifier_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/CNN-RGB_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/CNN-GREEN-MASK_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/SpotdetectionModel_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/AreaModel_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/LSTM-Classifier_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/FS-GREEN-MASK_results.h5'), PosixPath('/home/simon_g/src/eval/test_set/FS-RGB_results.h5')]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "files = list(Path(\"/home/simon_g/src/eval/test_set\").glob(\"*.h5\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic-Classifier_results        PRECISION:  85.15    RECALL/SENSITIVITY:  88.25    F1:  86.67    SPECIFICITY:  85.4    \n",
      "CNN-RGB_results                 PRECISION:  98.92    RECALL/SENSITIVITY:  98.29    F1:  98.6     SPECIFICITY:  98.99   \n",
      "CNN-GREEN-MASK_results          PRECISION:  99.14    RECALL/SENSITIVITY:  98.72    F1:  98.93    SPECIFICITY:  99.19   \n",
      "SpotdetectionModel_results      PRECISION:  83.51    RECALL/SENSITIVITY:  51.92    F1:  64.03    SPECIFICITY:  90.26   \n",
      "AreaModel_results               PRECISION:  91.19    RECALL/SENSITIVITY:  88.46    F1:  89.8     SPECIFICITY:  91.89   \n",
      "LSTM-Classifier_results         PRECISION:  97.57    RECALL/SENSITIVITY:  94.23    F1:  95.87    SPECIFICITY:  97.77   \n",
      "FS-GREEN-MASK_results           PRECISION:  99.35    RECALL/SENSITIVITY:  98.29    F1:  98.82    SPECIFICITY:  99.39   \n",
      "FS-RGB_results                  PRECISION:  98.49    RECALL/SENSITIVITY:  97.86    F1:  98.17    SPECIFICITY:  98.58   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_dict = {}\n",
    "for file in files: \n",
    "    \n",
    "    with h5py.File(file) as fout:\n",
    "        \n",
    "        target = np.array(fout[\"TARGET\"])\n",
    "        pred = np.array(fout[\"PRED\"])\n",
    "        \n",
    "    TP = len(np.where(np.logical_and(target == 1, pred == 1))[0])\n",
    "    TN = len(np.where(np.logical_and(target == 0, pred == 0))[0])\n",
    "    FP = len(np.where(np.logical_and(target == 0, pred == 1))[0])\n",
    "    FN = len(np.where(np.logical_and(target == 1, pred == 0))[0])\n",
    "    SPEC = np.round(TN / (TN + FP)*100,2)\n",
    "    \n",
    "    # Precision = TP / (TP + FP) \n",
    "    # Recall = TP / (TP + FN) \n",
    "    # F1 Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "    \n",
    "    precision = np.round(TP/(TP+FP)*100,2)\n",
    "    recall = np.round(TP/(TP+FN)*100,2)\n",
    "    F1 = np.round(2*precision*recall/(precision+recall),2)\n",
    "    \n",
    "    print(f\"{file.stem:<30}\", \" PRECISION: \", f\"{precision:<8}\", \"RECALL/SENSITIVITY: \", f\"{recall:<8}\", \"F1: \", f\"{F1:<8}\", \"SPECIFICITY: \", f\"{SPEC:<8}\")\n",
    "    results_dict[f\"{file.stem.replace('_results','')}\"] = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1\": F1,\n",
    "        \"specificity\": SPEC,\n",
    "        \"sensitivity\": recall\n",
    "    }\n",
    "    \n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"/home/simon_g/src/results/EVALUATION/metric_results.xlsx\", sheet_name=\"metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "files = list(Path(\"/home/simon_g/src/eval/test_set\").glob(\"*.h5\"))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_dict = {}\n",
    "for file in files: \n",
    "    \n",
    "    with h5py.File(file) as fout:\n",
    "        \n",
    "        target = np.array(fout[\"TARGET\"])\n",
    "        pred = np.array(fout[\"PRED\"])\n",
    "        \n",
    "    TP = len(np.where(np.logical_and(target == 1, pred == 1))[0])\n",
    "    TN = len(np.where(np.logical_and(target == 0, pred == 0))[0])\n",
    "    FP = len(np.where(np.logical_and(target == 0, pred == 1))[0])\n",
    "    FN = len(np.where(np.logical_and(target == 1, pred == 0))[0])\n",
    "    SPEC = np.round(TN / (TN + FP)*100,2)\n",
    "    \n",
    "    # Precision = TP / (TP + FP) \n",
    "    # Recall = TP / (TP + FN) \n",
    "    # F1 Score = 2 * Precision * Recall / (Precision + Recall)\n",
    "    \n",
    "    precision = np.round(TP/(TP+FP)*100,2)\n",
    "    recall = np.round(TP/(TP+FN)*100,2)\n",
    "    F1 = np.round(2*precision*recall/(precision+recall),2)\n",
    "    \n",
    "    print(f\"{file.stem:<30}\", \" PRECISION: \", f\"{precision:<8}\", \"RECALL/SENSITIVITY: \", f\"{recall:<8}\", \"F1: \", f\"{F1:<8}\", \"SPECIFICITY: \", f\"{SPEC:<8}\")\n",
    "    results_dict[f\"{file.stem.replace('_results','')}\"] = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"F1\": F1,\n",
    "        \"specificity\": SPEC,\n",
    "        \"sensitivity\": recall\n",
    "    }\n",
    "    \n",
    "results_df = pd.DataFrame(results_dict)\n",
    "results_df.to_excel(\"/home/simon_g/src/results/EVALUATION/metric_results.xlsx\", sheet_name=\"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of all plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_pred = pd.read_excel(\"/home/simon_g/src/results/EVALUATION/results_paper.xlsx\", sheet_name=\"predictions\", index_col=0).T\n",
    "df_diff = pd.read_excel(\"/home/simon_g/src/results/EVALUATION/results_paper.xlsx\", sheet_name=\"differences\", index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.reindex(\n",
    "    ['AreaModel', 'SpotdetectionModel', 'BasicClassifier', 'LSTMClassifier', 'ClassificationCNN', 'FeaturespaceClassifier', 'WeightedFeaturespaceClassifier']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df_diff.reindex(\n",
    "    ['AreaModel', 'SpotdetectionModel', 'BasicClassifier', 'LSTMClassifier', 'ClassificationCNN', 'FeaturespaceClassifier', 'WeightedFeaturespaceClassifier']\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('BB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d63b14cd6ab63ec18359f1ef4f96f0821945ecd9c555e0a621512114c620b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
